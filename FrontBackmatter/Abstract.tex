%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
% \addcontentsline{toc}{chapter}{\tocEntry{Abstract}}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}
The latest developments in the field of machine learning (ML) can have profound
consequences on how to process the information recorded by the fundamental physics
experiments like the ones preformed at the Large Hadron Collider (LHC). The dataset
output by the latter are indeed characterised by a very large size and tremendous
complexity, features which made ML techniques particularly suited for direct application.
As shown in previous works, deep networks can tackle problems of signal vs background
discrimination starting from low level quantities (\eg~particle four-momenta). The
training of such networks requires though a non negligible computing power, which in the
end turns into the main limitation of such an approach. The smart usage of computing
resources, in particular of clusters of computing nodes, exploiting modern “big data”
architectures could overcome this limitation. The proposal for this thesis work consists
indeed in setting up, test and benchmark various computing infrastructure options for the
training of a deep neural network aiming at the discrimination between signal (New
Physics) and background (Standard Model) in a dataset from the CMS experiment at the LHC.

\vfill

\begin{otherlanguage}{italian}
 \pdfbookmark[1]{Sommario}{Sommario}
 \chapter*{Sommario}
 Gli ultimi sviluppi nel campo del machine learning (ML) possono avere profonde
 conseguenze in come vengono processate le informazioni ottenute dai più importanti
 esperimenti di fisica come quelli che vengono effettuati con il Large Hadron Collider
 (LHC). I dataset ottenuti in questo modo sono caratterizzati da un ampio e complesso
 insieme di features, il che rende le tecniche del ML particolarmente adatte ad
 un'applicazione diretta. Come visto in lavori precedenti, le deep networks possono
 affrontare problemi di discriminizzazione segnale contro rumore partendo da quantità
 primitive (\eg~i quadrimomenti delle particelle). L'allenamento di queste reti richiede
 una potenza di calcolo non indifferente, il che è la principale limitazione di questo
 approccio. L'uso intelligente delle risorse di calcolo, in particolare l'utilizzo di
 cluster di computer, può essere utilizzato insieme a moderne tecniche di "big data" per
 superare queste limitazioni. Lo scopo di questo lavoro di tesi consiste infatti
 nello sviluppare, testare e confrontare diverse infrastrutture di calcolo per
 l'allenamento di una deep neural network considerando un problema di discriminizzazione
 tra segnale (Nuova Fisica) e rumore (Modello Standard) con un dataset dall'esperimento
 CMS all'LHC.
 
\end{otherlanguage}

\endgroup

\vfill
